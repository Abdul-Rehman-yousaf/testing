{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coursera_end_to_end_ml_lab_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Pwfj3xqlprxu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# change these to try this notebook out\n",
        "BUCKET = 'qwiklabs-gcp-24c583ad897245ef'\n",
        "PROJECT = 'qwiklabs-gcp-24c583ad897245ef'\n",
        "REGION = 'us-central1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t3LPg43pps2p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['BUCKET'] = BUCKET\n",
        "os.environ['PROJECT'] = PROJECT\n",
        "os.environ['REGION'] = REGION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MI0jMRaepxxz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
        "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U88u0R7Epzea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%bash\n",
        "ls *.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yH27i06_pzcF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TmhIgXImpzWZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Determine CSV, label, and key columns\n",
        "CSV_COLUMNS = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks,key'.split(',')\n",
        "LABEL_COLUMN = 'weight_pounds'\n",
        "KEY_COLUMN = 'key'\n",
        "\n",
        "# Set default values for each CSV column\n",
        "DEFAULTS = [[0.0], ['null'], [0.0], ['null'], [0.0], ['nokey']]\n",
        "TRAIN_STEPS = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ojFAnGBdpzMq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an input function reading a file using the Dataset API\n",
        "# Then provide the results to the Estimator API\n",
        "def read_dataset(filename, mode, batch_size = 512):\n",
        "  def _input_fn():\n",
        "    def decode_csv(value_column):\n",
        "      # TODO #1: Use tf.decode_csv to parse the provided line\n",
        "      columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
        "      # TODO #2: Make a Python dict.  The keys are the column names, the values are from the parsed data\n",
        "      features = dict(zip(CSV_COLUMNS, columns))\n",
        "      # TODO #3: Return a tuple of features, label where features is a Python dict and label a float\n",
        "      label = features.pop(LABEL_COLUMN)\n",
        "      return features, label\n",
        "    \n",
        "    # TODO #4: Use tf.gfile.Glob to create list of files that match pattern\n",
        "    file_list = None\n",
        "    file_list = tf.gfile.Glob(filename)\n",
        "    # Create dataset from file list\n",
        "    dataset = (tf.data.TextLineDataset(file_list)  # Read text file\n",
        "                 .map(decode_csv))  # Transform each elem by applying decode_csv fn\n",
        "    \n",
        "    # TODO #5: In training mode, shuffle the dataset and repeat indefinitely\n",
        "    #                (Look at the API for tf.data.dataset shuffle)\n",
        "    #          The mode input variable will be tf.estimator.ModeKeys.TRAIN if in training mode\n",
        "    #          Tell the dataset to provide data in batches of batch_size \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      num_epochs = None\n",
        "      dataset = dataset.shuffle(buffer_size=10*batch_size)\n",
        "    else:\n",
        "        num_epochs = 1 #end-of-input after this\n",
        "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
        "\n",
        "    # This will now return batches of features, label\n",
        "    return dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "#     return dataset\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ogk3MBeGp6gp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define feature columns\n",
        "def get_categorical(name, values):\n",
        "    return tf.feature_column.indicator_column(\n",
        "        tf.feature_column.categorical_column_with_vocabulary_list(name, values))\n",
        "\n",
        "def get_cols():\n",
        "    # define column types\n",
        "    [\\\n",
        "     get_categorical('is_male', ['False', 'True', 'Unknown']),\n",
        "     tf.feature_column.numeric_column('mother_age'),\n",
        "     get_categorical('plurality', ['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', 'Quintuplets(5)']),\n",
        "     tf.feature_column.numeric_column(gestation_weeks')\n",
        "    ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bvJvQHdKp6eV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create serving input function to be able to serve predictions later using provided inputs\n",
        "def serving_input_fn():\n",
        "    feature_placeholders = {\n",
        "        'is_male': tf.placeholder(tf.string, [None]),\n",
        "        'mother_age': tf.placeholder(tf.float32, [None]),\n",
        "        'plurality': tf.placeholder(tf.string, [None]),\n",
        "        'gestation_weeks': tf.placeholder(tf.float32, [None])\n",
        "    }\n",
        "    features = {\n",
        "        key: tf.expand_dims(tensor, -1)\n",
        "        for key, tensor in feature_placeholders.items()\n",
        "    }\n",
        "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yjCV94UzpyWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create estimator to train and evaluate\n",
        "def train_and_evaluate(output_dir):\n",
        "  EVAL_INTERVAL = 300\n",
        "  run_config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL,\n",
        "                                      keep_checkpoint_max = 3)\n",
        "  # TODO #1: Create your estimator\n",
        "  # DNN estimator\n",
        "  estimator = tf.estimator.DNNRegressor(model_dir=output_dir,\n",
        "                                       feature_columns = get_cols(),\n",
        "                                       hidden_units = [64, 32],\n",
        "                                       config= run_config)  \n",
        "  # Linear Regressor  \n",
        "  #estimator = tf.estimator.LinearRegressor(model_dir=output_dir, feature_columns = get_cols())\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "                       # TODO #2: Call read_dataset passing in the training CSV file and the appropriate mode\n",
        "                       input_fn = read_dataset('train.csv', mode=tf.estimator.ModeKeys.TRAIN),\n",
        "                       max_steps = TRAIN_STEPS)\n",
        "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "                       # TODO #3: Call read_dataset passing in the evaluation CSV file and the appropriate mode\n",
        "                       input_fn = read_dataset('train.csv', mode=tf.estimator.ModeKeys.EVAL),\n",
        "                       steps = None,\n",
        "                       start_delay_secs = 60, # start evaluating after N seconds\n",
        "                       throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds\n",
        "                       exporters = exporter)\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OffMP3fiqLOl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run the model\n",
        "shutil.rmtree('babyweight_trained', ignore_errors = True) # start fresh each time\n",
        "train_and_evaluate('babyweight_trained')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZVDOWm5qPoJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Monitor and experiment with training "
      ]
    },
    {
      "metadata": {
        "id": "Wooav5HaqMDR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.datalab.ml import TensorBoard\n",
        "TensorBoard().start('./babyweight_trained')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRU1j46HqTsj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for pid in TensorBoard.list()['pid']:\n",
        "  TensorBoard().stop(pid)\n",
        "  print('Stopped TensorBoard with pid {}'.format(pid))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}